% Self-organizing maps usually rely on a predetermined topology of the neural space (the map), which is either a rectangular or a hexagonal Cartesian grid. When the intrinsic dimension of  the input space is much higher than the allowed dimension of the neural space, then the self-organizing map can be ill-formed. To overcome this problem in  high dimensional input spaces. We propose a variation of the self organizing map algorithm, where we consider random placement of neurons on a high-dimensional manifold. The positions of the neural units are drawn from a blue noise distribution from which various topologies can be derived. These topologies possess  random but controllable discontinuities that allow for a flexible self-organization, especially with high-dimensional data. The proposed algorithm has been tested on one-, two- and three-dimensions tasks as well as on MNIST handwritten digits dataset. Furthermore, we investigate the reorganization of the self-organizing maps when we either remove or add neurons to the map. To analyze the results we use spectral analysis and topological data analysis tools. 
%

\textbf{Abstract.} We propose a variation of the self organizing map algorithm by considering the random placement of neurons on a two-dimensional manifold, following a blue noise distribution from which various topologies can be derived. These topologies possess random (but controllable) discontinuities that allow for a more flexible self-organization, especially with high-dimensional data. The proposed algorithm is tested on one-, two- and three-dimensions tasks as well as on the MNIST handwritten digits dataset and validated using spectral analysis and topological data analysis tools. We also demonstrate the ability of the randomized self-organizing map to gracefully reorganize itself in case of neural lesion and/or neurogenesis.\par

% \textbf{Keywords.} Self Organization, Neural Networks, Vector Quantization, Voronoi Tesselation, Neural Map Topology
